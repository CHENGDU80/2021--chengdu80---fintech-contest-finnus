{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e3b54d4",
   "metadata": {},
   "source": [
    "# Final_Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b424410a",
   "metadata": {},
   "source": [
    "# 0.Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "859bf9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import imblearn\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "rs=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a4c5c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../Processed_Data/\"\n",
    "outpath = \"../PredictionResult/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01371b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y\n",
    "label_risk_company_sample = pd.read_csv(\"../Data/Online_Data/trainning_data/label_risk_company.csv”)\n",
    "label_risk_company_sample = label_risk_company_sample.drop_duplicates()\n",
    "\n",
    "# X\n",
    "company_ar = pd.read_csv(path+\"company_ar_processed.csv\")\n",
    "company_ar_alterstockinfo = pd.read_csv(path+\"company_ar_alterstockinfo_processed.csv\")\n",
    "company_ar_assetsinfo = pd.read_csv(path+\"company_ar_assetsinfo_processed.csv\")\n",
    "company_ar_nz = pd.read_csv(path+\"company_ar_nz_processed.csv\")\n",
    "company_ar_processed = pd.read_csv(path+\"company_ar_processed.csv\")\n",
    "company_ar_socialfee = pd.read_csv(path+\"company_ar_socialfee_processed.csv\")\n",
    "company_base_info = pd.read_csv(path+\"company_base_info_processed.csv\")\n",
    "company_modify = pd.read_csv(path+\"company_modify_processed.csv\")\n",
    "el_company_history_inv = pd.read_csv(path+\"el_company_history_inv_processed.csv\")\n",
    "el_company_history_manager = pd.read_csv(path+\"el_company_history_manager_processed.csv\")\n",
    "tax_abnormal = pd.read_csv(path+\"tax_abnormal_processed.csv\")\n",
    "tax_company = pd.read_csv(path+\"tax_company_processed.csv\")\n",
    "tax_qianshui = pd.read_csv(path+\"tax_qianshui_processed.csv\")\n",
    "tax_year = pd.read_csv(path+\"tax_year_processed.csv\")\n",
    "\n",
    "\n",
    "df_list =[company_ar, company_ar_alterstockinfo, company_ar_nz, company_base_info,company_ar_socialfee, \\\n",
    "          company_modify, el_company_history_inv, el_company_history_manager, tax_abnormal, tax_company, \\\n",
    "          tax_qianshui ,tax_year]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cda58c0",
   "metadata": {},
   "source": [
    "## 1. Join Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88f86820",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =label_risk_company_sample\n",
    "for i in df_list:\n",
    "    df = pd.merge(df, i , on=\"entid\",how='outer').copy()\n",
    "df_all = df.copy()\n",
    "df_all_2 = df.copy()\n",
    "df = df.dropna(subset=[\"CaseType\"])\n",
    "df = df.drop([\"entid\",\"id\"],axis=1)\n",
    "df.to_csv(\"df.csv\")\n",
    "\n",
    "df_drop = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a05cb1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(df.isnull(), cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be8d0391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CaseType</th>\n",
       "      <th>women_ratio</th>\n",
       "      <th>Vol/transaction_per_year</th>\n",
       "      <th>net_change_per_year</th>\n",
       "      <th>unique_number_of_SH_involved_per_year</th>\n",
       "      <th>total_transaction_number_per_year</th>\n",
       "      <th>MEMNNUM</th>\n",
       "      <th>FARNUM</th>\n",
       "      <th>ANNNEWMEM</th>\n",
       "      <th>ANNREDMEM</th>\n",
       "      <th>...</th>\n",
       "      <th>other_operating_cost</th>\n",
       "      <th>retained_profits</th>\n",
       "      <th>gross_profit</th>\n",
       "      <th>main_business_gross</th>\n",
       "      <th>incometax_actual</th>\n",
       "      <th>profit_margin</th>\n",
       "      <th>operating_profit_margin</th>\n",
       "      <th>other_expense</th>\n",
       "      <th>net_asset</th>\n",
       "      <th>main_biz_profit_margin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.681896</td>\n",
       "      <td>0.861137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.151294</td>\n",
       "      <td>-2.365160</td>\n",
       "      <td>-1.023133</td>\n",
       "      <td>1.867823</td>\n",
       "      <td>-0.575773</td>\n",
       "      <td>2.477843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.444446</td>\n",
       "      <td>0.134651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.430861</td>\n",
       "      <td>0.879706</td>\n",
       "      <td>-0.223222</td>\n",
       "      <td>-0.689344</td>\n",
       "      <td>-0.347430</td>\n",
       "      <td>-1.121208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2080</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2081</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2082</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.110127</td>\n",
       "      <td>0.243137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023342</td>\n",
       "      <td>0.206735</td>\n",
       "      <td>0.273269</td>\n",
       "      <td>0.734497</td>\n",
       "      <td>0.734650</td>\n",
       "      <td>0.268797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2084</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2085 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CaseType  women_ratio  Vol/transaction_per_year  net_change_per_year  \\\n",
       "0          3.0     0.250000                       0.0                  0.0   \n",
       "1          3.0     0.000000                       0.0                  0.0   \n",
       "2          0.0     0.444444                       0.0                  0.0   \n",
       "3          3.0     0.000000                       0.0                  0.0   \n",
       "4          2.0     0.000000                       0.0                  0.0   \n",
       "...        ...          ...                       ...                  ...   \n",
       "2080       3.0     0.545455                       0.0                  0.0   \n",
       "2081       3.0     0.000000                       0.0                  0.0   \n",
       "2082       3.0     0.000000                       0.0                  0.0   \n",
       "2083       3.0     0.000000                       0.0                  0.0   \n",
       "2084       3.0     0.000000                       0.0                  0.0   \n",
       "\n",
       "      unique_number_of_SH_involved_per_year  \\\n",
       "0                                       0.0   \n",
       "1                                       0.0   \n",
       "2                                       0.0   \n",
       "3                                       0.0   \n",
       "4                                       0.0   \n",
       "...                                     ...   \n",
       "2080                                    0.0   \n",
       "2081                                    0.0   \n",
       "2082                                    0.0   \n",
       "2083                                    0.0   \n",
       "2084                                    0.0   \n",
       "\n",
       "      total_transaction_number_per_year  MEMNNUM  FARNUM  ANNNEWMEM  \\\n",
       "0                                   0.0      0.0     0.0        0.0   \n",
       "1                                   0.0      0.0     0.0        0.0   \n",
       "2                                   0.0      0.0     0.0        0.0   \n",
       "3                                   0.0      0.0     0.0        0.0   \n",
       "4                                   0.0      0.0     0.0        0.0   \n",
       "...                                 ...      ...     ...        ...   \n",
       "2080                                0.0      0.0     0.0        0.0   \n",
       "2081                                0.0      0.0     0.0        0.0   \n",
       "2082                                0.0      0.0     0.0        0.0   \n",
       "2083                                0.0      0.0     0.0        0.0   \n",
       "2084                                0.0      0.0     0.0        0.0   \n",
       "\n",
       "      ANNREDMEM  ...  other_operating_cost  retained_profits  gross_profit  \\\n",
       "0           0.0  ...              0.000000          0.000000           0.0   \n",
       "1           0.0  ...             -0.681896          0.861137           0.0   \n",
       "2           0.0  ...              0.000000          0.000000           0.0   \n",
       "3           0.0  ...              0.000000          0.000000           0.0   \n",
       "4           0.0  ...              0.444446          0.134651           0.0   \n",
       "...         ...  ...                   ...               ...           ...   \n",
       "2080        0.0  ...              0.000000          0.000000           0.0   \n",
       "2081        0.0  ...              0.000000          0.000000           0.0   \n",
       "2082        0.0  ...              0.000000          0.000000           0.0   \n",
       "2083        0.0  ...              1.110127          0.243137           0.0   \n",
       "2084        0.0  ...              0.000000          0.000000           0.0   \n",
       "\n",
       "      main_business_gross  incometax_actual  profit_margin  \\\n",
       "0                     0.0          0.000000       0.000000   \n",
       "1                     0.0         -0.151294      -2.365160   \n",
       "2                     0.0          0.000000       0.000000   \n",
       "3                     0.0          0.000000       0.000000   \n",
       "4                     0.0         -0.430861       0.879706   \n",
       "...                   ...               ...            ...   \n",
       "2080                  0.0          0.000000       0.000000   \n",
       "2081                  0.0          0.000000       0.000000   \n",
       "2082                  0.0          0.000000       0.000000   \n",
       "2083                  0.0          0.023342       0.206735   \n",
       "2084                  0.0          0.000000       0.000000   \n",
       "\n",
       "      operating_profit_margin  other_expense  net_asset  \\\n",
       "0                    0.000000       0.000000   0.000000   \n",
       "1                   -1.023133       1.867823  -0.575773   \n",
       "2                    0.000000       0.000000   0.000000   \n",
       "3                    0.000000       0.000000   0.000000   \n",
       "4                   -0.223222      -0.689344  -0.347430   \n",
       "...                       ...            ...        ...   \n",
       "2080                 0.000000       0.000000   0.000000   \n",
       "2081                 0.000000       0.000000   0.000000   \n",
       "2082                 0.000000       0.000000   0.000000   \n",
       "2083                 0.273269       0.734497   0.734650   \n",
       "2084                 0.000000       0.000000   0.000000   \n",
       "\n",
       "      main_biz_profit_margin  \n",
       "0                   0.000000  \n",
       "1                   2.477843  \n",
       "2                   0.000000  \n",
       "3                   0.000000  \n",
       "4                  -1.121208  \n",
       "...                      ...  \n",
       "2080                0.000000  \n",
       "2081                0.000000  \n",
       "2082                0.000000  \n",
       "2083                0.268797  \n",
       "2084                0.000000  \n",
       "\n",
       "[2085 rows x 84 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.fillna(0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da9eee9",
   "metadata": {},
   "source": [
    "# 2. Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4592405d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "RANDOM_STATE = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d520cc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([\"CaseType\"],axis=1)\n",
    "y = df[\"CaseType\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=rs,stratify=y) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263c2023",
   "metadata": {},
   "source": [
    "# 3. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217b27ef",
   "metadata": {},
   "source": [
    "## 3.1.Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d2cb274",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.38      0.45      0.42        11\n",
      "         1.0       0.33      0.09      0.14        11\n",
      "         2.0       1.00      0.65      0.79        20\n",
      "         3.0       0.95      0.98      0.96       375\n",
      "\n",
      "    accuracy                           0.93       417\n",
      "   macro avg       0.67      0.54      0.58       417\n",
      "weighted avg       0.92      0.93      0.92       417\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(random_state=rs,verbosity = 0,estimators=100, max_depth=10, learning_rate=1)\n",
    "xgb.fit(X_train,y_train)\n",
    "print(classification_report(y_test, xgb.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b1c1014",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_test= pd.read_csv(\"../Data/Online_Data/test_data/test_data.csvtest_data.csv\")\n",
    "\n",
    "ind = X_train.columns.values.tolist()\n",
    "ind.append(\"entid\")\n",
    "\n",
    "for i in df_list:\n",
    "    act_test = pd.merge(act_test, i , on=\"entid\",how='left').copy()\n",
    "act_test = act_test[ind]\n",
    "\n",
    "ent = act_test[\"entid\"]\n",
    "\n",
    "act_test_X = act_test.drop([\"entid\"],axis=1)\n",
    "act_test_X = act_test_X.fillna(0)\n",
    "\n",
    "df_out = pd.DataFrame()\n",
    "df_out[\"entid\"] = ent\n",
    "df_out[\"predict\"] = xgb.predict(act_test_X)\n",
    "\n",
    "#df_out.to_csv(outpath+\"df_out_1.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5574e9",
   "metadata": {},
   "source": [
    "## 3.2.Semi Supervised for Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0b58b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>women_ratio</th>\n",
       "      <th>Vol/transaction_per_year</th>\n",
       "      <th>net_change_per_year</th>\n",
       "      <th>unique_number_of_SH_involved_per_year</th>\n",
       "      <th>total_transaction_number_per_year</th>\n",
       "      <th>MEMNNUM</th>\n",
       "      <th>FARNUM</th>\n",
       "      <th>ANNNEWMEM</th>\n",
       "      <th>ANNREDMEM</th>\n",
       "      <th>concentration(ESG)</th>\n",
       "      <th>...</th>\n",
       "      <th>other_operating_cost</th>\n",
       "      <th>retained_profits</th>\n",
       "      <th>gross_profit</th>\n",
       "      <th>main_business_gross</th>\n",
       "      <th>incometax_actual</th>\n",
       "      <th>profit_margin</th>\n",
       "      <th>operating_profit_margin</th>\n",
       "      <th>other_expense</th>\n",
       "      <th>net_asset</th>\n",
       "      <th>main_biz_profit_margin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2085</th>\n",
       "      <td>0.457746</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.274038</td>\n",
       "      <td>-7.253495e+05</td>\n",
       "      <td>3.296052e+06</td>\n",
       "      <td>3.296052e+06</td>\n",
       "      <td>-0.092693</td>\n",
       "      <td>-0.029356</td>\n",
       "      <td>-0.030853</td>\n",
       "      <td>6.688114e+06</td>\n",
       "      <td>2.118802e+07</td>\n",
       "      <td>3.180760e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2086</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2087</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>243165.0</td>\n",
       "      <td>0.621989</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>870000.177025</td>\n",
       "      <td>-3.133073e+06</td>\n",
       "      <td>2.685150e+07</td>\n",
       "      <td>2.387000e+07</td>\n",
       "      <td>-0.666003</td>\n",
       "      <td>-0.296341</td>\n",
       "      <td>-0.342939</td>\n",
       "      <td>2.374930e+07</td>\n",
       "      <td>7.634000e+08</td>\n",
       "      <td>1.960067e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2088</th>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030642</td>\n",
       "      <td>-1.463999e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.118862</td>\n",
       "      <td>29089.227030</td>\n",
       "      <td>29087.308515</td>\n",
       "      <td>2.863983e+04</td>\n",
       "      <td>3.195016e+04</td>\n",
       "      <td>2.752229e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2089</th>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.454968</td>\n",
       "      <td>-4.633384e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.404115</td>\n",
       "      <td>336110.971449</td>\n",
       "      <td>336114.067484</td>\n",
       "      <td>1.408145e+05</td>\n",
       "      <td>8.552473e+07</td>\n",
       "      <td>1.781334e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12303</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.787543</td>\n",
       "      <td>-1.828851e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.566075</td>\n",
       "      <td>-0.049365</td>\n",
       "      <td>0.896717</td>\n",
       "      <td>-1.340319e+00</td>\n",
       "      <td>-4.240097e-01</td>\n",
       "      <td>-1.619164e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12304</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12305</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12306</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12307</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10223 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       women_ratio  Vol/transaction_per_year  net_change_per_year  \\\n",
       "2085      0.457746                       0.0             0.000000   \n",
       "2086      0.000000                       0.0             0.000000   \n",
       "2087      0.500000                  243165.0             0.621989   \n",
       "2088      0.809524                       0.0             0.000000   \n",
       "2089      0.588235                       0.0             0.000000   \n",
       "...            ...                       ...                  ...   \n",
       "12303     0.000000                       0.0             0.000000   \n",
       "12304     0.000000                       0.0             0.000000   \n",
       "12305     0.000000                       0.0             0.000000   \n",
       "12306     0.000000                       0.0             0.000000   \n",
       "12307     0.000000                       0.0             0.000000   \n",
       "\n",
       "       unique_number_of_SH_involved_per_year  \\\n",
       "2085                                     0.0   \n",
       "2086                                     0.0   \n",
       "2087                                     2.0   \n",
       "2088                                     0.0   \n",
       "2089                                     0.0   \n",
       "...                                      ...   \n",
       "12303                                    0.0   \n",
       "12304                                    0.0   \n",
       "12305                                    0.0   \n",
       "12306                                    0.0   \n",
       "12307                                    0.0   \n",
       "\n",
       "       total_transaction_number_per_year  MEMNNUM  FARNUM  ANNNEWMEM  \\\n",
       "2085                                 0.0      0.0     0.0        0.0   \n",
       "2086                                 0.0      5.0     7.0        0.0   \n",
       "2087                                 2.0      0.0     0.0        0.0   \n",
       "2088                                 0.0      0.0     0.0        0.0   \n",
       "2089                                 0.0      0.0     0.0        0.0   \n",
       "...                                  ...      ...     ...        ...   \n",
       "12303                                0.0      0.0     0.0        0.0   \n",
       "12304                                0.0      0.0     0.0        0.0   \n",
       "12305                                0.0      0.0     0.0        0.0   \n",
       "12306                                0.0      0.0     0.0        0.0   \n",
       "12307                                0.0      0.0     0.0        0.0   \n",
       "\n",
       "       ANNREDMEM  concentration(ESG)  ...  other_operating_cost  \\\n",
       "2085         0.0                 0.0  ...             -0.274038   \n",
       "2086         9.0                 1.0  ...              0.000000   \n",
       "2087         0.0                 0.0  ...         870000.177025   \n",
       "2088         0.0                 0.0  ...              0.030642   \n",
       "2089         0.0                 0.0  ...             -0.454968   \n",
       "...          ...                 ...  ...                   ...   \n",
       "12303        0.0                 0.0  ...             -0.787543   \n",
       "12304        0.0                 0.0  ...              0.000000   \n",
       "12305        0.0                 0.0  ...              0.000000   \n",
       "12306        0.0                 0.0  ...              0.000000   \n",
       "12307        0.0                 0.0  ...              0.000000   \n",
       "\n",
       "       retained_profits  gross_profit  main_business_gross  incometax_actual  \\\n",
       "2085      -7.253495e+05  3.296052e+06         3.296052e+06         -0.092693   \n",
       "2086       0.000000e+00  0.000000e+00         0.000000e+00          0.000000   \n",
       "2087      -3.133073e+06  2.685150e+07         2.387000e+07         -0.666003   \n",
       "2088      -1.463999e+04  0.000000e+00         0.000000e+00         -0.118862   \n",
       "2089      -4.633384e+04  0.000000e+00         0.000000e+00          0.404115   \n",
       "...                 ...           ...                  ...               ...   \n",
       "12303     -1.828851e+00  0.000000e+00         0.000000e+00         -0.566075   \n",
       "12304      0.000000e+00  0.000000e+00         0.000000e+00          0.000000   \n",
       "12305      0.000000e+00  0.000000e+00         0.000000e+00          0.000000   \n",
       "12306      0.000000e+00  0.000000e+00         0.000000e+00          0.000000   \n",
       "12307      0.000000e+00  0.000000e+00         0.000000e+00          0.000000   \n",
       "\n",
       "       profit_margin  operating_profit_margin  other_expense     net_asset  \\\n",
       "2085       -0.029356                -0.030853   6.688114e+06  2.118802e+07   \n",
       "2086        0.000000                 0.000000   0.000000e+00  0.000000e+00   \n",
       "2087       -0.296341                -0.342939   2.374930e+07  7.634000e+08   \n",
       "2088    29089.227030             29087.308515   2.863983e+04  3.195016e+04   \n",
       "2089   336110.971449            336114.067484   1.408145e+05  8.552473e+07   \n",
       "...              ...                      ...            ...           ...   \n",
       "12303      -0.049365                 0.896717  -1.340319e+00 -4.240097e-01   \n",
       "12304       0.000000                 0.000000   0.000000e+00  0.000000e+00   \n",
       "12305       0.000000                 0.000000   0.000000e+00  0.000000e+00   \n",
       "12306       0.000000                 0.000000   0.000000e+00  0.000000e+00   \n",
       "12307       0.000000                 0.000000   0.000000e+00  0.000000e+00   \n",
       "\n",
       "       main_biz_profit_margin  \n",
       "2085             3.180760e+07  \n",
       "2086             0.000000e+00  \n",
       "2087             1.960067e+07  \n",
       "2088             2.752229e+00  \n",
       "2089             1.781334e+00  \n",
       "...                       ...  \n",
       "12303           -1.619164e+00  \n",
       "12304            0.000000e+00  \n",
       "12305            0.000000e+00  \n",
       "12306            0.000000e+00  \n",
       "12307            0.000000e+00  \n",
       "\n",
       "[10223 rows x 83 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = df_all.iloc[len(df_all[df_all[\"CaseType\"]>-1]):,:]\n",
    "df_add = df_all.drop([\"CaseType\",\"id\",\"entid\"],axis=1)\n",
    "df_add = df_add.fillna(0)\n",
    "df_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2220b3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = xgb.predict(df_add)\n",
    "df_add[\"CaseType\"] = pred\n",
    "df_add = df_add[df_add[\"CaseType\"]!=3]\n",
    "pred_exc3 = df_add[\"CaseType\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8f53b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>women_ratio</th>\n",
       "      <th>Vol/transaction_per_year</th>\n",
       "      <th>net_change_per_year</th>\n",
       "      <th>unique_number_of_SH_involved_per_year</th>\n",
       "      <th>total_transaction_number_per_year</th>\n",
       "      <th>MEMNNUM</th>\n",
       "      <th>FARNUM</th>\n",
       "      <th>ANNNEWMEM</th>\n",
       "      <th>ANNREDMEM</th>\n",
       "      <th>concentration(ESG)</th>\n",
       "      <th>...</th>\n",
       "      <th>other_operating_cost</th>\n",
       "      <th>retained_profits</th>\n",
       "      <th>gross_profit</th>\n",
       "      <th>main_business_gross</th>\n",
       "      <th>incometax_actual</th>\n",
       "      <th>profit_margin</th>\n",
       "      <th>operating_profit_margin</th>\n",
       "      <th>other_expense</th>\n",
       "      <th>net_asset</th>\n",
       "      <th>main_biz_profit_margin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2093</th>\n",
       "      <td>0.552941</td>\n",
       "      <td>703531.0</td>\n",
       "      <td>1.930562</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.117522</td>\n",
       "      <td>-2.507856e+06</td>\n",
       "      <td>4.912001e+06</td>\n",
       "      <td>4.912000e+06</td>\n",
       "      <td>658804.712534</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>5.857556e-03</td>\n",
       "      <td>6.356381e+06</td>\n",
       "      <td>7.580067e+10</td>\n",
       "      <td>4.213149e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174454</td>\n",
       "      <td>-1.329334e+04</td>\n",
       "      <td>7.366323e+04</td>\n",
       "      <td>7.366356e+04</td>\n",
       "      <td>1.229492</td>\n",
       "      <td>-0.058699</td>\n",
       "      <td>-5.869963e-02</td>\n",
       "      <td>2.134356e+05</td>\n",
       "      <td>7.254557e+05</td>\n",
       "      <td>3.742660e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974204</td>\n",
       "      <td>-3.895536e-03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.487024</td>\n",
       "      <td>-0.000976</td>\n",
       "      <td>-2.082122e-04</td>\n",
       "      <td>1.132695e+00</td>\n",
       "      <td>1.983649e+05</td>\n",
       "      <td>1.131650e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2147</th>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.180429</td>\n",
       "      <td>-4.333846e+02</td>\n",
       "      <td>3.308919e+05</td>\n",
       "      <td>3.308911e+05</td>\n",
       "      <td>0.984256</td>\n",
       "      <td>-0.001766</td>\n",
       "      <td>-3.628083e-03</td>\n",
       "      <td>4.301330e+05</td>\n",
       "      <td>6.666603e+04</td>\n",
       "      <td>2.453692e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2148</th>\n",
       "      <td>0.459459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.198247</td>\n",
       "      <td>3.939701e+05</td>\n",
       "      <td>1.200921e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>13930.336316</td>\n",
       "      <td>0.221560</td>\n",
       "      <td>1.818068e-07</td>\n",
       "      <td>2.005972e-01</td>\n",
       "      <td>9.749052e-01</td>\n",
       "      <td>1.841667e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12204</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12209</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12211</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.688894</td>\n",
       "      <td>-4.085149e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.909287</td>\n",
       "      <td>2.962914</td>\n",
       "      <td>-4.296644e+00</td>\n",
       "      <td>-9.505243e-01</td>\n",
       "      <td>4.999990e+05</td>\n",
       "      <td>-4.158605e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12242</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12262</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.477583</td>\n",
       "      <td>8.522586e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>294954.606593</td>\n",
       "      <td>-0.098721</td>\n",
       "      <td>-2.671432e-01</td>\n",
       "      <td>3.958396e+06</td>\n",
       "      <td>8.100450e+07</td>\n",
       "      <td>-2.971498e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>843 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       women_ratio  Vol/transaction_per_year  net_change_per_year  \\\n",
       "2093      0.552941                  703531.0             1.930562   \n",
       "2098      1.000000                       0.0             0.000000   \n",
       "2139      0.000000                       0.0             0.000000   \n",
       "2147      0.783784                       0.0             0.000000   \n",
       "2148      0.459459                       0.0             0.000000   \n",
       "...            ...                       ...                  ...   \n",
       "12204     1.000000                       0.0             0.000000   \n",
       "12209     0.666667                       0.0             0.000000   \n",
       "12211     0.000000                       0.0             0.000000   \n",
       "12242     0.000000                       0.0             0.000000   \n",
       "12262     0.000000                       0.0             0.000000   \n",
       "\n",
       "       unique_number_of_SH_involved_per_year  \\\n",
       "2093                                     1.0   \n",
       "2098                                     0.0   \n",
       "2139                                     0.0   \n",
       "2147                                     0.0   \n",
       "2148                                     0.0   \n",
       "...                                      ...   \n",
       "12204                                    0.0   \n",
       "12209                                    0.0   \n",
       "12211                                    0.0   \n",
       "12242                                    0.0   \n",
       "12262                                    0.0   \n",
       "\n",
       "       total_transaction_number_per_year  MEMNNUM  FARNUM  ANNNEWMEM  \\\n",
       "2093                                 1.5      0.0     0.0        0.0   \n",
       "2098                                 0.0      0.0     0.0        0.0   \n",
       "2139                                 0.0      0.0     0.0        0.0   \n",
       "2147                                 0.0      0.0     0.0        0.0   \n",
       "2148                                 0.0      0.0     0.0        0.0   \n",
       "...                                  ...      ...     ...        ...   \n",
       "12204                                0.0      0.0     0.0        0.0   \n",
       "12209                                0.0      0.0     0.0        0.0   \n",
       "12211                                0.0      0.0     0.0        0.0   \n",
       "12242                                0.0      0.0     0.0        0.0   \n",
       "12262                                0.0      0.0     0.0        0.0   \n",
       "\n",
       "       ANNREDMEM  concentration(ESG)  ...  other_operating_cost  \\\n",
       "2093         0.0                 0.0  ...             -1.117522   \n",
       "2098         0.0                 0.0  ...              0.174454   \n",
       "2139         0.0                 0.0  ...              0.974204   \n",
       "2147         0.0                 0.0  ...             -0.180429   \n",
       "2148         0.0                 0.0  ...              0.198247   \n",
       "...          ...                 ...  ...                   ...   \n",
       "12204        0.0                 0.0  ...              0.000000   \n",
       "12209        0.0                 0.0  ...              0.000000   \n",
       "12211        0.0                 0.0  ...             -0.688894   \n",
       "12242        0.0                 0.0  ...              0.000000   \n",
       "12262        0.0                 0.0  ...              2.477583   \n",
       "\n",
       "       retained_profits  gross_profit  main_business_gross  incometax_actual  \\\n",
       "2093      -2.507856e+06  4.912001e+06         4.912000e+06     658804.712534   \n",
       "2098      -1.329334e+04  7.366323e+04         7.366356e+04          1.229492   \n",
       "2139      -3.895536e-03  0.000000e+00         0.000000e+00          2.487024   \n",
       "2147      -4.333846e+02  3.308919e+05         3.308911e+05          0.984256   \n",
       "2148       3.939701e+05  1.200921e+06         0.000000e+00      13930.336316   \n",
       "...                 ...           ...                  ...               ...   \n",
       "12204      0.000000e+00  0.000000e+00         0.000000e+00          0.000000   \n",
       "12209      0.000000e+00  0.000000e+00         0.000000e+00          0.000000   \n",
       "12211     -4.085149e-01  0.000000e+00         0.000000e+00          0.909287   \n",
       "12242      0.000000e+00  0.000000e+00         0.000000e+00          0.000000   \n",
       "12262      8.522586e-01  0.000000e+00         0.000000e+00     294954.606593   \n",
       "\n",
       "       profit_margin  operating_profit_margin  other_expense     net_asset  \\\n",
       "2093        0.000194             5.857556e-03   6.356381e+06  7.580067e+10   \n",
       "2098       -0.058699            -5.869963e-02   2.134356e+05  7.254557e+05   \n",
       "2139       -0.000976            -2.082122e-04   1.132695e+00  1.983649e+05   \n",
       "2147       -0.001766            -3.628083e-03   4.301330e+05  6.666603e+04   \n",
       "2148        0.221560             1.818068e-07   2.005972e-01  9.749052e-01   \n",
       "...              ...                      ...            ...           ...   \n",
       "12204       0.000000             0.000000e+00   0.000000e+00  0.000000e+00   \n",
       "12209       0.000000             0.000000e+00   0.000000e+00  0.000000e+00   \n",
       "12211       2.962914            -4.296644e+00  -9.505243e-01  4.999990e+05   \n",
       "12242       0.000000             0.000000e+00   0.000000e+00  0.000000e+00   \n",
       "12262      -0.098721            -2.671432e-01   3.958396e+06  8.100450e+07   \n",
       "\n",
       "       main_biz_profit_margin  \n",
       "2093             4.213149e+06  \n",
       "2098             3.742660e+05  \n",
       "2139             1.131650e+01  \n",
       "2147             2.453692e+05  \n",
       "2148             1.841667e+06  \n",
       "...                       ...  \n",
       "12204            0.000000e+00  \n",
       "12209            0.000000e+00  \n",
       "12211           -4.158605e+00  \n",
       "12242            0.000000e+00  \n",
       "12262           -2.971498e+00  \n",
       "\n",
       "[843 rows x 83 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_add = df_add.drop([\"CaseType\"],axis=1)\n",
    "df_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35b15d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train,df_add]).copy()\n",
    "y_train = pd.concat([pd.DataFrame(y_train),pd.DataFrame(pred_exc3,columns=[\"CaseType\"])]).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8f9cc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, estimators=100, gamma=0,\n",
       "              gpu_id=-1, importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=1, max_delta_step=0, max_depth=10,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=8, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=6, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b7aed07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.33      0.45      0.38        11\n",
      "         1.0       0.20      0.09      0.13        11\n",
      "         2.0       0.80      0.60      0.69        20\n",
      "         3.0       0.94      0.96      0.95       375\n",
      "\n",
      "    accuracy                           0.91       417\n",
      "   macro avg       0.57      0.53      0.54       417\n",
      "weighted avg       0.90      0.91      0.90       417\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, xgb.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9dc1ddad",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_test= pd.read_csv(\"../Data/Online_Data/test_data/test_data.csvtest_data.csv\")\n",
    "\n",
    "ind = X_train.columns.values.tolist()\n",
    "ind.append(\"entid\")\n",
    "\n",
    "for i in df_list:\n",
    "    act_test = pd.merge(act_test, i , on=\"entid\",how='left').copy()\n",
    "act_test = act_test[ind]\n",
    "\n",
    "ent = act_test[\"entid\"]\n",
    "\n",
    "act_test_X = act_test.drop([\"entid\"],axis=1)\n",
    "act_test_X = act_test_X.fillna(0)\n",
    "\n",
    "df_out = pd.DataFrame()\n",
    "df_out[\"entid\"] = ent\n",
    "df_out[\"predict\"] = xgb.predict(act_test_X)\n",
    "\n",
    "#df_out.to_csv(outpath+\"df_out_1-1.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e565772",
   "metadata": {},
   "source": [
    "## 3.3.Drop Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d29b3aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CaseType</th>\n",
       "      <th>women_ratio</th>\n",
       "      <th>Vol/transaction_per_year</th>\n",
       "      <th>net_change_per_year</th>\n",
       "      <th>unique_number_of_SH_involved_per_year</th>\n",
       "      <th>total_transaction_number_per_year</th>\n",
       "      <th>MEMNNUM</th>\n",
       "      <th>FARNUM</th>\n",
       "      <th>ANNNEWMEM</th>\n",
       "      <th>ANNREDMEM</th>\n",
       "      <th>...</th>\n",
       "      <th>other_operating_cost</th>\n",
       "      <th>retained_profits</th>\n",
       "      <th>gross_profit</th>\n",
       "      <th>main_business_gross</th>\n",
       "      <th>incometax_actual</th>\n",
       "      <th>profit_margin</th>\n",
       "      <th>operating_profit_margin</th>\n",
       "      <th>other_expense</th>\n",
       "      <th>net_asset</th>\n",
       "      <th>main_biz_profit_margin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.681896</td>\n",
       "      <td>0.861137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.151294</td>\n",
       "      <td>-2.365160</td>\n",
       "      <td>-1.023133</td>\n",
       "      <td>1.867823</td>\n",
       "      <td>-0.575773</td>\n",
       "      <td>2.477843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.444446</td>\n",
       "      <td>0.134651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.430861</td>\n",
       "      <td>0.879706</td>\n",
       "      <td>-0.223222</td>\n",
       "      <td>-0.689344</td>\n",
       "      <td>-0.347430</td>\n",
       "      <td>-1.121208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2080</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2081</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2082</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.110127</td>\n",
       "      <td>0.243137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023342</td>\n",
       "      <td>0.206735</td>\n",
       "      <td>0.273269</td>\n",
       "      <td>0.734497</td>\n",
       "      <td>0.734650</td>\n",
       "      <td>0.268797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2084</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2085 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CaseType  women_ratio  Vol/transaction_per_year  net_change_per_year  \\\n",
       "0          3.0     0.250000                       NaN                  NaN   \n",
       "1          3.0          NaN                       NaN                  NaN   \n",
       "2          0.0     0.444444                       NaN                  NaN   \n",
       "3          3.0     0.000000                       NaN                  NaN   \n",
       "4          2.0          NaN                       NaN                  NaN   \n",
       "...        ...          ...                       ...                  ...   \n",
       "2080       3.0     0.545455                       NaN                  NaN   \n",
       "2081       3.0          NaN                       NaN                  NaN   \n",
       "2082       3.0          NaN                       NaN                  NaN   \n",
       "2083       3.0          NaN                       NaN                  NaN   \n",
       "2084       3.0          NaN                       NaN                  NaN   \n",
       "\n",
       "      unique_number_of_SH_involved_per_year  \\\n",
       "0                                       NaN   \n",
       "1                                       NaN   \n",
       "2                                       NaN   \n",
       "3                                       NaN   \n",
       "4                                       NaN   \n",
       "...                                     ...   \n",
       "2080                                    NaN   \n",
       "2081                                    NaN   \n",
       "2082                                    NaN   \n",
       "2083                                    NaN   \n",
       "2084                                    NaN   \n",
       "\n",
       "      total_transaction_number_per_year  MEMNNUM  FARNUM  ANNNEWMEM  \\\n",
       "0                                   NaN      NaN     NaN        NaN   \n",
       "1                                   NaN      NaN     NaN        NaN   \n",
       "2                                   NaN      NaN     NaN        NaN   \n",
       "3                                   NaN      NaN     NaN        NaN   \n",
       "4                                   NaN      NaN     NaN        NaN   \n",
       "...                                 ...      ...     ...        ...   \n",
       "2080                                NaN      NaN     NaN        NaN   \n",
       "2081                                NaN      NaN     NaN        NaN   \n",
       "2082                                NaN      NaN     NaN        NaN   \n",
       "2083                                NaN      NaN     NaN        NaN   \n",
       "2084                                NaN      NaN     NaN        NaN   \n",
       "\n",
       "      ANNREDMEM  ...  other_operating_cost  retained_profits  gross_profit  \\\n",
       "0           NaN  ...                   NaN               NaN           NaN   \n",
       "1           NaN  ...             -0.681896          0.861137           0.0   \n",
       "2           NaN  ...                   NaN               NaN           NaN   \n",
       "3           NaN  ...                   NaN               NaN           NaN   \n",
       "4           NaN  ...              0.444446          0.134651           0.0   \n",
       "...         ...  ...                   ...               ...           ...   \n",
       "2080        NaN  ...                   NaN               NaN           NaN   \n",
       "2081        NaN  ...                   NaN               NaN           NaN   \n",
       "2082        NaN  ...                   NaN               NaN           NaN   \n",
       "2083        NaN  ...              1.110127          0.243137           0.0   \n",
       "2084        NaN  ...                   NaN               NaN           NaN   \n",
       "\n",
       "      main_business_gross  incometax_actual  profit_margin  \\\n",
       "0                     NaN               NaN            NaN   \n",
       "1                     0.0         -0.151294      -2.365160   \n",
       "2                     NaN               NaN            NaN   \n",
       "3                     NaN               NaN            NaN   \n",
       "4                     0.0         -0.430861       0.879706   \n",
       "...                   ...               ...            ...   \n",
       "2080                  NaN               NaN            NaN   \n",
       "2081                  NaN               NaN            NaN   \n",
       "2082                  NaN               NaN            NaN   \n",
       "2083                  0.0          0.023342       0.206735   \n",
       "2084                  NaN               NaN            NaN   \n",
       "\n",
       "      operating_profit_margin  other_expense  net_asset  \\\n",
       "0                         NaN            NaN        NaN   \n",
       "1                   -1.023133       1.867823  -0.575773   \n",
       "2                         NaN            NaN        NaN   \n",
       "3                         NaN            NaN        NaN   \n",
       "4                   -0.223222      -0.689344  -0.347430   \n",
       "...                       ...            ...        ...   \n",
       "2080                      NaN            NaN        NaN   \n",
       "2081                      NaN            NaN        NaN   \n",
       "2082                      NaN            NaN        NaN   \n",
       "2083                 0.273269       0.734497   0.734650   \n",
       "2084                      NaN            NaN        NaN   \n",
       "\n",
       "      main_biz_profit_margin  \n",
       "0                        NaN  \n",
       "1                   2.477843  \n",
       "2                        NaN  \n",
       "3                        NaN  \n",
       "4                  -1.121208  \n",
       "...                      ...  \n",
       "2080                     NaN  \n",
       "2081                     NaN  \n",
       "2082                     NaN  \n",
       "2083                0.268797  \n",
       "2084                     NaN  \n",
       "\n",
       "[2085 rows x 84 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "789a1f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_col = []\n",
    "(len(df_drop)-df_drop.isnull().sum().values)/len(df_drop)\n",
    "\n",
    "for i in range(len((len(df_drop)-df_drop.isnull().sum().values)/len(df_drop))):\n",
    "#    if ((len(df_drop)-df_drop.isnull().sum().values)/len(df_drop))[i] < 0.8:\n",
    "    if ((len(df_drop)-df_drop.isnull().sum().values)/len(df_drop))[i] < 0.5:\n",
    "        drop_col.append(df_drop.columns[i])\n",
    "#drop_col\n",
    "\n",
    "df_drop = df_drop.drop(drop_col,axis=1)\n",
    "df_drop = df_drop.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e6e75412",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([\"CaseType\"],axis=1)\n",
    "y = df_drop[\"CaseType\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=rs,stratify=y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "666a3a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=8, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=6, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier(random_state=rs,verbosity = 0)\n",
    "xgb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "30e127e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.40      0.36      0.38        11\n",
      "         1.0       0.50      0.09      0.15        11\n",
      "         2.0       1.00      0.60      0.75        20\n",
      "         3.0       0.94      0.99      0.96       375\n",
      "\n",
      "    accuracy                           0.93       417\n",
      "   macro avg       0.71      0.51      0.56       417\n",
      "weighted avg       0.92      0.93      0.92       417\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, xgb.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "48923294",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_test= pd.read_csv(\"../Data/Online_Data/test_data/test_data.csvtest_data.csv\")\n",
    "\n",
    "ind = X_train.columns.values.tolist()\n",
    "ind.append(\"entid\")\n",
    "\n",
    "for i in df_list:\n",
    "    act_test = pd.merge(act_test, i , on=\"entid\",how='left').copy()\n",
    "act_test = act_test[ind]\n",
    "\n",
    "ent = act_test[\"entid\"]\n",
    "\n",
    "act_test_X = act_test.drop([\"entid\"],axis=1)\n",
    "act_test_X = act_test_X.fillna(0)\n",
    "\n",
    "df_out = pd.DataFrame()\n",
    "df_out[\"entid\"] = ent\n",
    "df_out[\"predict\"] = xgb.predict(act_test_X)\n",
    "\n",
    "#df_out.to_csv(output_path+\"df_out_2.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0666c4ba",
   "metadata": {},
   "source": [
    "## 3.4.SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e6ca2bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE(random_state=rs)\n",
    "X_train, y_train = oversample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78e485c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.29      0.45      0.36        11\n",
      "         1.0       0.50      0.36      0.42        11\n",
      "         2.0       0.41      0.60      0.49        20\n",
      "         3.0       0.96      0.93      0.94       375\n",
      "\n",
      "    accuracy                           0.88       417\n",
      "   macro avg       0.54      0.59      0.55       417\n",
      "weighted avg       0.90      0.88      0.89       417\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(random_state=rs,verbosity = 0, estimators = 150, max_depth = 15 ,learning_rate = 1)\n",
    "xgb.fit(X_train,y_train)\n",
    "print(classification_report(y_test, xgb.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e1adc8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_test= pd.read_csv(\"../Data/Online_Data/test_data/test_data.csvtest_data.csv\")\n",
    "\n",
    "ind = X_train.columns.values.tolist()\n",
    "ind.append(\"entid\")\n",
    "\n",
    "for i in df_list:\n",
    "    act_test = pd.merge(act_test, i , on=\"entid\",how='left').copy()\n",
    "act_test = act_test[ind]\n",
    "\n",
    "ent = act_test[\"entid\"]\n",
    "\n",
    "act_test_X = act_test.drop([\"entid\"],axis=1)\n",
    "act_test_X = act_test_X.fillna(0)\n",
    "\n",
    "df_out = pd.DataFrame()\n",
    "df_out[\"entid\"] = ent\n",
    "df_out[\"predict\"] = xgb.predict(act_test_X)\n",
    "\n",
    "#df_out.to_csv(output_path+\"df_out_3.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f097a0",
   "metadata": {},
   "source": [
    "## 3.5.Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cf0369fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('xgbclassifier',\n",
       "                 XGBClassifier(base_score=None, booster=None,\n",
       "                               colsample_bylevel=None, colsample_bynode=None,\n",
       "                               colsample_bytree=None, gamma=None, gpu_id=None,\n",
       "                               importance_type='gain',\n",
       "                               interaction_constraints=None, learning_rate=None,\n",
       "                               max_delta_step=None, max_depth=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, n_estimators=100,\n",
       "                               n_jobs=None, num_parallel_tree=None,\n",
       "                               random_state=6, reg_alpha=None, reg_lambda=None,\n",
       "                               scale_pos_weight=None, subsample=None,\n",
       "                               tree_method=None, validate_parameters=None,\n",
       "                               verbosity=0))])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build pipeline\n",
    "sscaler = StandardScaler()\n",
    "xgb = XGBClassifier(random_state=rs,verbosity = 0)\n",
    "\n",
    "pipe_xgb = make_pipeline(sscaler, xgb)\n",
    "pipe_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26645a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\gamis\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# set parameters for GridSearch tunning\n",
    "xgb_params = {\n",
    "    'xgbclassifier__n_estimators':[100,150],\n",
    "    'xgbclassifier__learning_rate': [0.001, 0.01, 1],\n",
    "    'xgbclassifier__max_depth':[5,10,15]\n",
    "}\n",
    "\n",
    "grid = RandomizedSearchCV(pipe_xgb, xgb_params, scoring='f1_macro')\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b5dfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid.best_estimator_.predict(X_test)\n",
    "y_pred_prob = grid.predict_proba(X_test)\n",
    "\n",
    "print('f1_score', f1_score(y_test, y_pred, average='weighted'))\n",
    "print('roc_auc_score', roc_auc_score(y_test, y_pred_prob, multi_class='ovr'))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6332837a",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_test= pd.read_csv(\"../Data/Online_Data/test_data/test_data.csvtest_data.csv\")\n",
    "\n",
    "ind = X_train.columns.values.tolist()\n",
    "ind.append(\"entid\")\n",
    "\n",
    "for i in df_list:\n",
    "    act_test = pd.merge(act_test, i , on=\"entid\",how='left').copy()\n",
    "act_test = act_test[ind]\n",
    "\n",
    "ent = act_test[\"entid\"]\n",
    "\n",
    "act_test_X = act_test.drop([\"entid\"],axis=1)\n",
    "act_test_X = act_test_X.fillna(0)\n",
    "\n",
    "df_out = pd.DataFrame()\n",
    "df_out[\"entid\"] = ent\n",
    "df_out[\"CaseType\"] = grid.predict(act_test_X)\n",
    "\n",
    "df_out.to_csv(output_path + \"result.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
